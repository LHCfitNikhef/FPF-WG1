{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4196a694-2798-4b26-b454-f391a8d7c9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "284b53e8-dbad-45ef-973d-c92cb50a5e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the matplotlib plotting styles\n",
    "CURR_PATH = pathlib.Path().parent\n",
    "MPLSTYLE = CURR_PATH.joinpath(\"../plotstyle.mplstyle\")\n",
    "plt.style.use(MPLSTYLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1097bb54-2f73-493e-a2f8-132f858475a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_txt_pd(otype: str = \"inclusive\", charge: str = \"nu\") -> pd.DataFrame:\n",
    "    \n",
    "    path = f\"clipped_nan_binned_sysevents_FASERv2_{otype}_{charge}.txt\"\n",
    "    fpath = CURR_PATH.joinpath(f\"stat_syst_uncertainties/{path}\")\n",
    "    \n",
    "    colnames = [\n",
    "        \"x_lower\", \n",
    "        \"x_upper\", \n",
    "        \"x_avg\", \n",
    "        \"Q2_lower\", \n",
    "        \"Q2_upper\", \n",
    "        \"Q2_avg\", \n",
    "        \"E_nu_lower\", \n",
    "        \"E_nu_upper\", \n",
    "        \"E_nu_avg\", \n",
    "        \"d^sigma/dxdQ2\", \n",
    "        \"N_events\", \n",
    "        \"N_events_errs\", \n",
    "        \"N_sys_errs\", \n",
    "        \"Percent_error_theta\", \n",
    "        \"Percent_error_Elepton\", \n",
    "        \"Percent_error_Ehadron\", \n",
    "        \"MC_Samples\",\n",
    "    ]\n",
    "    \n",
    "    return pd.read_csv(fpath, skiprows=2, delim_whitespace=True, names=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ad77d5-6ad3-45a4-b687-9326f09ff028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = read_txt_pd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3fe6f5c-6eab-4517-b58c-e2749df98adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_input(otype: str = \"inclusive\", charge: str = \"nu\"):\n",
    "    # Read and Parse the central values\n",
    "    data_name = f\"diffxsec-FASERv2_{otype}_{charge}\"\n",
    "    pdfname = f\"{NNPDF40_nnlo_as_01180_iso}\"\n",
    "    path_cv = CURR_PATH.joinpath(f\"pineappl_tables/{data_name}-a1_{pdfname}.txt\")\n",
    "    column = 3 if charge == \"nu\" else 4 # Select the correct projectile\n",
    "    sigma = np.loadtxt(pathlib.Path(path_cv) , usecols=column, unpack=True, skiprows=1)\n",
    "    \n",
    "    # Extract the percentage error from the Lepton Energy\n",
    "    df_predictions = read_txt_pd(otype=otype, charge=charge)\n",
    "    # Compute the corresponding systematic errors\n",
    "    syst_error = sigma * df_predictions[\"Percent_error_Elepton\"].values\n",
    "    # Extract the statistical events error\n",
    "    num_events_error = df_predictions[\"N_events_errs\"]\n",
    "    stat_error = 1.0 / num_events_error * sigma\n",
    "    \n",
    "    # Add the statistical and systematic in quadrature\n",
    "    comb_error = np.sqrt(syst_error**2 + stat_error**2)\n",
    "    \n",
    "    return {\n",
    "        \"stat_error\": stat_error,\n",
    "        \"syst_error\": syst_error,\n",
    "        \"comb_error\": comb_error,\n",
    "        \"sigma\": sigma,\n",
    "        \"dataset_suffix\": charge,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3898246b-381c-496e-a74f-2db3ad8d7d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fluctuate_data(central: np.ndarray, covmat: np.ndarray) -> np.ndarray:\n",
    "    cholesky = np.linalg.cholesky(covmat)\n",
    "    random_samples = np.random.randn(central.shape[0])\n",
    "    \n",
    "    shift_data = cholesky @ random_samples\n",
    "    pseudodata = central + shift_data\n",
    "    \n",
    "    return pseudodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa7a1d76-b2d1-4e72-b303-6485ca44d4e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_error, syst_error, combined_error, sigma = load_input()\n",
    "# Compute the covariance matrix\n",
    "stat_covmat = np.diag(stat_error**2)\n",
    "syst_covmat = np.diag(syst_error**2)\n",
    "combined_covmat = np.diag(combined_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782c139-f4bb-432a-86d6-640c65da91c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
