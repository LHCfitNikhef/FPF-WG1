\clearpage
\section{Analysis settings}
\label{sec:settings}

In this section, we describe the analysis settings adopted to quantify
the impact of LHC neutrino measurements on the proton and nuclear PDFs.
%
First of all, we discuss the calculation of inclusive and charm structure functions
and their interpolation in terms of fast grids. 
%
Second, we review the Hessian profiling framework and how it is applied
in this work to proton and nuclear PDFs.
%
Third, we indicate the implementation of the LHC neutrino pseudo-data in the
NNPDF framework and the settings of the subsequent global PDF analysis.

\subsection{Structure function calculation}
\label{subsec:dis_sf_calculations}

The procedure described in Sect.~\ref{sec:dis_pseudodata} returns
$N_{\rm bin}$ bins of LHC neutrino pseudo-data $\mathcal{O}_i^{{\rm (exp)}}$, Eq.~(\ref{eq:pseudo_data}), covering the $(x,Q^2,E_\nu)$ kinematic region accessible by the experiment,
together with the associated statistical and systematic uncertainties.
%
The calculation of this pseudo-data relies on the corresponding set of
theoretical predictions for the same observables $\mathcal{O}_i^{{\rm (th)}}$,
Eq.~(\ref{eq:theory_dis_projections}).
%
Here we evaluate inclusive and charm DIS structure functions with the
{\sc\small YADISM}~\cite{yadism,Candido:2023utz} program
interfaced to {\sc\small PineAPPL}~\cite{Carrazza:2020gss, christopher_schwan_2023_7995675}
to return a fast interpolation grid admitting a generic PDF input.
%
DGLAP evolution effects between the scale $Q_0$ at which PDFs are evaluated
and the data scale $Q$ are provided by {\sc\small EKO}~\cite{Candido:2022tld}.

The resulting {\sc\small PineAPPL} grids provide a fast evaluation
of Eq.~(\ref{eq:theory_dis_projections}) for an arbitrary choice of the
input PDFs at the initial scale $Q_0$, with the latter accessed via their
{\sc\small LHAPDF} interface~\cite{Buckley:2014ana}.
%
Whenever pseudo-data is generated, it is crucial to adopt common inputs with
the subsequent PDF analysis.
%
For instance, if one aims to include the LHC neutrino data into the NNPDF4.0
NNLO determination, $\mathcal{O}_i^{{\rm (th)}}$ must be evaluated also at NNLO
and also using
NNPDF4.0 as input for consistency, else artificial tensions between theory
and data would be introduced during the fit biasing the results.

By means of this theoretical pipeline, predictions for
DIS inclusive structure functions on an isoscalar target $N$ are computed
using
\be
\label{eq:neutrino_DIS_xsec}
\frac{d^2\sigma^{\nu N}(x,Q^2,y)}{dxdy} =  \frac{G_F^2s/4\pi}{\lp 1+Q^2/m_W^2\rp^2}\lc Y_+F^{\nu N}_2(x,Q^2) - y^2F^{\nu N}_L(x,Q^2) +Y_- xF^{\nu N}_3(x,Q^2)\rc  \, ,
\ee
with an analogous formula for antineutrino scattering with the sign of $xF_3$ flipped.
%
A {\sc\small PineAPPL} interpolation grid for
Eq.~(\ref{eq:neutrino_DIS_xsec}) is evaluated at the $(x,Q^2,E_\nu)$ bins
for which pseudo-data is generated using DGLAP evolution and coefficient
functions at $\mathcal{O}\lp \alpha_s^2\rp$ and accounting for target mass effects.
%
No higher-twists corrections to the structure functions are included, since we cut
data with $W^2 \ge 12.5$ GeV in order to suppress them.
%
Deviations from isoscalarity and nuclear modifications with respect
to a free isoscalar target are accounted for at the input PDF level,
leaving the grid entering the evaluation of Eq.~(\ref{eq:neutrino_DIS_xsec}) unchanged.
%
No heavy quark mass effects are considered for at the level of these inclusive structure functions.

Concerning charm structure functions, for experiments with charm tagging
capabilities theoretical predictions are evaluated for
\be
\label{eq:neutrino_DIS_xsec}
\frac{d^2\sigma^{\nu N}_c(x,Q^2,y)}{dxdy} =  \frac{G_F^2s/4\pi}{\lp 1+Q^2/m_W^2\rp^2}\lc Y_+F_{2,c}^{\nu N}(x,Q^2) - y^2F^{\nu N}_{L,c}(x,Q^2) +Y_- xF^{\nu N}_{3,c}(x,Q^2)\rc  \, ,
\ee
with the DIS charm structure functions evaluated in the FONLL general-mass variable-flavour-number
scheme~\cite{Forte:2010ta,Ball:2011mu,Faura:2020oom} in order to account for charm mass effects.
%
Eq.~(\ref{eq:neutrino_DIS_xsec}) is computed with $\mathcal{O}\lp \alpha_s^2\rp$ massless
coefficient functions and $\mathcal{O}\lp \alpha_s\rp$ massive ones, given
that the $\mathcal{O}\lp \alpha_s^2\rp$ massive calculation~\cite{Gao:2017kkx} is not publicly available.
%
Nevertheless, the $\mathcal{O}\lp \alpha_s\rp$ massive coefficient functions
encapsulate the dominant charm mass dependence of the double differential
cross-section.
%
We assume 100\% efficiency in charm tagging and do not impose acceptance cuts on the charm
quark or $D$-meson kinematics (the only acceptance requirements are applied to the final-state
charged lepton, as indicated in  Table~\ref{tab:FPF_experiments}).

We note that experiments without charm-tagging capabilities can still identify charm production
events by means of the dimuon final state,
\be
\nu + N \to \mu^+ + c~(\to D) + X \to \mu^+ + \mu^- +X \, ,
\ee
by profiting from the semileptonic decays of the $D$-meson leading
to the characteristic signature of two opposite-sign muons.
%
In this case, the  differential charm production cross-section Eq.~(\ref{eq:neutrino_DIS_xsec})
must be accompanied by the corresponding branching ratio
\be
\frac{d^2\sigma^{\nu N}_c(x,Q^2,y)}{dxdy}\mathcal{B}\lp c \to D \to \mu + X\rp \, ,
\ee
which given that $\mathcal{B}\sim 10\%$ suppresses the reconstructed charm
production event yields by around an order of magnitude.
%
For experiments reconstructing the dimuon final state,
we also apply the muon acceptance criteria to both muons.

\subsection{Hessian profiling}
\label{sec:profiling}

In this work we consider two complementary approaches in order to assess the
impact of LHC neutrino data on the proton and nuclear PDFs.
%
On the one hand, the Hessian profiling of a prior proton or
nuclear PDF set, which here are taken to be PDF4LHC21~\cite{PDF4LHCWorkingGroup:2022cjn} and
EPPS21~\cite{Eskola:2021nhw} respectively.
%
On the other hand, the inclusion of the LHC neutrino structure functions
on the NNPDF global analysis framework~\cite{NNPDF:2021uiq,NNPDF:2021njg}.
%
Here we summarise the details of the Hessian profiling procedure and
outline how it is applied in our work.


The expected impact of the FPF data on global PDF fits is assessed by a profiling procedure~\cite{Paukkunen:2014zia, Schmidt:2018hvu, AbdulKhalek:2018rok, HERAFitterdevelopersTeam:2015cre}, based on minimizing the function
%TODO correlations are also included here, as we hopefully get there in the end -- if not, remove terms involving correlations+pseudodata
\begin{equation}
\chi^2 = 
\sum_{i=1}^{N_{\textrm{bins}}} 
\frac{\left(  \sigma_i^{\textrm{pd}}
            + \Gamma_i^{\alpha,\textrm{pd}}
              b_\alpha^{\textrm{pd}}
            - \sigma_i^{\textrm{th}}
            - \Gamma_i^{\beta,\textrm{th}}
              b_\beta^{\textrm{th}}
     \right)^2
     }{\Delta_i^2}
+ \sum_\alpha (b_\alpha^{\textrm{pd}})^2
+ \sum_\beta  (b_\beta^{\textrm{th}})^2 \, .
\label{eq:profilingchi2}
\end{equation}
Here the pseudodata 
$\sigma_i^{\textrm{pd}}$ 
is obtained from the central theoretical prediction 
$\sigma_i^{\textrm{th}}$ 
for each bin $i$ out of $N_{\textrm{bins}}$ by varying it within bounds obtained from the statistical (systematic) uncertainties 
$\delta_i^{\textrm{stat}}$ ($\delta_i^{\textrm{syst}}$), 
obtained in the procedure described in Section~\ref{sec:pseudo-data_generation}, 
as 

\begin{equation}
\sigma_i^{\textrm{pd}}
=
\sigma_i^{\textrm{th}}
\left( 1 + r_i \sqrt{     (\delta_i^{\textrm{stat}})^2
                      + (f \delta_i^{\textrm{syst}})^2 }
\right).
\end{equation}
Here, $r_i$ is a univariate Gaussian random number and $f = 0.5$ an effective correction factor 
accounting for the improved constraining power of the same pseudodata set using correlated systematics, compared to solely adding all sources of uncertainty in quadrature.
%
The correlated uncertainties for the pseudodata and the theoretical prediction 
are contained in the nuisance parameter vectors $b^{\textrm{pd}}$ and $b^{\textrm{th}}$, respectively, and the uncorrelated uncertainties in $\Delta_i$.
%
Their effect on $\sigma^{\textrm{th}}$ and $\sigma^{\textrm{pd}}$
is described by the matrices $\Gamma_i^{\textrm{pd}}$ and $\Gamma_i^{\textrm{th}}$.
The indices $\alpha$ and $\beta$ then run over the uncertainty nuisance parameters for the pseudodata and the theoretical prediction, respectively.
%
The nuisance parameter values $b^{\textrm{th(min)}}$ that minimize Eq.~\eqref{eq:profilingchi2} give the central PDFs $f'_0$ optimized to the profiled dataset in the form
\begin{equation}
f_0' = f_0
      + \sum_\beta b_\beta^{\textrm{th(min)}} 
        \left(  \frac{f_\beta^+   -  f_\beta^- }{2}
              -    b_\beta^{\textrm{th(min)}}
                \frac{f_\beta^+ + f_\beta^- - 2f_0}{2}
        \right),
\end{equation}
where $f_0$ is the original central PDF and the up and down variation eigenvectors are given by $f^+, f^-$. The decrease in the uncertainties of the shifted PDFs indicates the enhancement that including the FPF data in the global PDF fit could bring. Here, the profiling studies are performed using version 2.2.1 of the \textsc{xFitter} open-source QCD analysis framework~\cite{Alekhin:2014irh, Bertone:2017tig, xFitter:2022zjb, xFitter:web}.
%

To this end, a new interface between  {\sc\small PineAPPL} and {\sc\small xFitter} has been developed and is available with the open-source {\sc\small xFitter} code.

\subsection{Implementation in NNPDF}


